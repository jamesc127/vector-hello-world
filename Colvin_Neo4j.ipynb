{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/osaeed-ds/vector-hello/blob/main/Osaeed_Neo4j.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RUs9nlOEc7k"
      },
      "source": [
        "# **Neo4j Vector as a Vector Database**\n",
        "This is a hello world exercise based on the Vector Search quickstart on the LangChain website.\n",
        "https://python.langchain.com/docs/integrations/vectorstores/neo4jvector\n",
        "\n",
        "The dataset did not work in the example (did not specify where to get the file) so I substituted my own dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iU-bLR8EtGY"
      },
      "source": [
        "## **Prerequisites**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RypgSL-ZwoYO",
        "outputId": "1a659c40-8472-4eb7-de6f-21903b003ebe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting neo4j\n",
            "  Downloading neo4j-5.13.0.tar.gz (192 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.3/192.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting openai\n",
            "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/1e/9f/385c25502f437686e4aa715969e5eaf5c2cb5e5ffa7c5cdd52f3c6ae967a/openai-0.28.1-py3-none-any.whl.metadata\n",
            "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting tiktoken\n",
            "  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/0b/c9/cd8a2e95078f94a40bf1408c0ac353570114976fda90fc8da62d3c85fff6/tiktoken-0.5.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain\n",
            "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/e0/2c/1c5e358f954ca23cd20c9220439450a601436ca054a28860e3e1753e64ec/langchain-0.0.312-py3-none-any.whl.metadata\n",
            "  Downloading langchain-0.0.312-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/site-packages (from neo4j) (2023.3.post1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/site-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2023.10.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Obtaining dependency information for SQLAlchemy<3,>=1.4 from https://files.pythonhosted.org/packages/6d/69/75fd46366ae9c6d677adb2d4db30c12544216026cf5366e76670dde6c9ed/SQLAlchemy-2.0.21-cp310-cp310-macosx_10_9_x86_64.whl.metadata\n",
            "  Downloading SQLAlchemy-2.0.21-cp310-cp310-macosx_10_9_x86_64.whl.metadata (9.4 kB)\n",
            "Collecting anyio<4.0 (from langchain)\n",
            "  Obtaining dependency information for anyio<4.0 from https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl.metadata\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Obtaining dependency information for dataclasses-json<0.7,>=0.5.7 from https://files.pythonhosted.org/packages/21/1f/1cff009cff64420572b9f75b70e4a054095719179a172297dfdd65843162/dataclasses_json-0.6.1-py3-none-any.whl.metadata\n",
            "  Downloading dataclasses_json-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Obtaining dependency information for jsonpatch<2.0,>=1.33 from https://files.pythonhosted.org/packages/73/07/02e16ed01e04a374e644b575638ec7987ae846d25ad97bcc9945a3ee4b0e/jsonpatch-1.33-py2.py3-none-any.whl.metadata\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.43 (from langchain)\n",
            "  Obtaining dependency information for langsmith<0.1.0,>=0.0.43 from https://files.pythonhosted.org/packages/9b/6c/fd466f647634ef4a668ea109bf0892d7f78882ffe09500429081ed6dae4a/langsmith-0.0.43-py3-none-any.whl.metadata\n",
            "  Downloading langsmith-0.0.43-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/site-packages (from langchain) (1.26.0)\n",
            "Collecting pydantic<3,>=1 (from langchain)\n",
            "  Obtaining dependency information for pydantic<3,>=1 from https://files.pythonhosted.org/packages/73/66/0a72c9fcde42e5650c8d8d5c5c1873b9a3893018020c77ca8eb62708b923/pydantic-2.4.2-py3-none-any.whl.metadata\n",
            "  Downloading pydantic-2.4.2-py3-none-any.whl.metadata (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.6/158.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
            "  Obtaining dependency information for tenacity<9.0.0,>=8.1.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
            "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\n",
            "Collecting sniffio>=1.1 (from anyio<4.0->langchain)\n",
            "  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: exceptiongroup in /Users/james.colvin/Library/Python/3.10/lib/python/site-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Obtaining dependency information for marshmallow<4.0.0,>=3.18.0 from https://files.pythonhosted.org/packages/ed/3c/cebfdcad015240014ff08b883d1c0c427f2ba45ae8c6572851b6ef136cad/marshmallow-3.20.1-py3-none-any.whl.metadata\n",
            "  Downloading marshmallow-3.20.1-py3-none-any.whl.metadata (7.8 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Obtaining dependency information for typing-inspect<1,>=0.4.0 from https://files.pythonhosted.org/packages/65/f3/107a22063bf27bdccf2024833d3445f4eea42b2e598abfbd46f6a63b6cb0/typing_inspect-0.9.0-py3-none-any.whl.metadata\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Obtaining dependency information for jsonpointer>=1.9 from https://files.pythonhosted.org/packages/12/f6/0232cc0c617e195f06f810534d00b74d2f348fe71b2118009ad8ad31f878/jsonpointer-2.4-py2.py3-none-any.whl.metadata\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
            "  Obtaining dependency information for annotated-types>=0.4.0 from https://files.pythonhosted.org/packages/28/78/d31230046e58c207284c6b2c4e8d96e6d3cb4e52354721b944d3e1ee4aa5/annotated_types-0.6.0-py3-none-any.whl.metadata\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pydantic-core==2.10.1 (from pydantic<3,>=1->langchain)\n",
            "  Obtaining dependency information for pydantic-core==2.10.1 from https://files.pythonhosted.org/packages/33/50/e9ed10546bc169f49240e1bd5642fe2235a60bccfd5ec9e8f3dadee8932e/pydantic_core-2.10.1-cp310-cp310-macosx_10_7_x86_64.whl.metadata\n",
            "  Downloading pydantic_core-2.10.1-cp310-cp310-macosx_10_7_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.8.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
            "  Obtaining dependency information for greenlet!=0.4.17 from https://files.pythonhosted.org/packages/72/fb/f3d2fb411d2ddd08f0624023ff0f89faca0190b98bee9071689ef279f0e4/greenlet-3.0.0-cp310-cp310-macosx_10_9_universal2.whl.metadata\n",
            "  Downloading greenlet-3.0.0-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/james.colvin/Library/Python/3.10/lib/python/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.5.1-cp310-cp310-macosx_10_9_x86_64.whl (953 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.5/953.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.0.312-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached anyio-3.7.1-py3-none-any.whl (80 kB)\n",
            "Downloading dataclasses_json-0.6.1-py3-none-any.whl (27 kB)\n",
            "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langsmith-0.0.43-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m768.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.4.2-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.8/395.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.10.1-cp310-cp310-macosx_10_7_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.21-cp310-cp310-macosx_10_9_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
            "Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Downloading greenlet-3.0.0-cp310-cp310-macosx_10_9_universal2.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.6/261.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hUsing cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Building wheels for collected packages: neo4j\n",
            "  Building wheel for neo4j (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for neo4j: filename=neo4j-5.13.0-py3-none-any.whl size=265636 sha256=916036b948685bccdec13c6c399125b3a4e53103a5cf884770ae5777fb069d5e\n",
            "  Stored in directory: /Users/james.colvin/Library/Caches/pip/wheels/7b/1d/b6/1be3a1e9de57bc832b7fcebbbf884186d8155bb6f1cc45be99\n",
            "Successfully built neo4j\n",
            "Installing collected packages: tenacity, sniffio, pydantic-core, neo4j, mypy-extensions, marshmallow, jsonpointer, greenlet, annotated-types, typing-inspect, tiktoken, SQLAlchemy, pydantic, jsonpatch, anyio, openai, langsmith, dataclasses-json, langchain\n",
            "Successfully installed SQLAlchemy-2.0.21 annotated-types-0.6.0 anyio-3.7.1 dataclasses-json-0.6.1 greenlet-3.0.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.312 langsmith-0.0.43 marshmallow-3.20.1 mypy-extensions-1.0.0 neo4j-5.13.0 openai-0.28.1 pydantic-2.4.2 pydantic-core-2.10.1 sniffio-1.3.0 tenacity-8.2.3 tiktoken-0.5.1 typing-inspect-0.9.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install neo4j openai tiktoken langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "z3QPwu9GcK2v"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Neo4jVector\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.docstore.document import Document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLuJYzU3Dn4-"
      },
      "source": [
        "## **Embedding Engine**\n",
        "We will use Open AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QA-f7c0FcARc",
        "outputId": "16c2829a-834a-4984-dc22-fe0f6e4cb3fb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca0I4CHQghcH"
      },
      "source": [
        "## **Dataset**\n",
        "We will use the US Constitution as our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e-__1eIdzJg",
        "outputId": "e389dcfb-7612-4bb6-8a91-98206435cd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  291k    0  291k    0     0   580k      0 --:--:-- --:--:-- --:--:--  588k\n"
          ]
        }
      ],
      "source": [
        "!curl https://www.govinfo.gov/content/pkg/CDOC-110hdoc50/html/CDOC-110hdoc50.htm > constitution.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb7aQvXtgoVR"
      },
      "source": [
        "## **Generate Embeddings**\n",
        "Use LangChain to chunk the dataset and use OpenAI for embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKnH7zE0cULn",
        "outputId": "90e5928f-6b82-4600-a471-a72395399425"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Created a chunk of size 4562, which is longer than the specified 1000\n",
            "Created a chunk of size 21641, which is longer than the specified 1000\n",
            "Created a chunk of size 6612, which is longer than the specified 1000\n",
            "Created a chunk of size 2609, which is longer than the specified 1000\n",
            "Created a chunk of size 2239, which is longer than the specified 1000\n",
            "Created a chunk of size 1870, which is longer than the specified 1000\n",
            "Created a chunk of size 2679, which is longer than the specified 1000\n",
            "Created a chunk of size 1111, which is longer than the specified 1000\n",
            "Created a chunk of size 1860, which is longer than the specified 1000\n",
            "Created a chunk of size 2927, which is longer than the specified 1000\n",
            "Created a chunk of size 2233, which is longer than the specified 1000\n",
            "Created a chunk of size 2149, which is longer than the specified 1000\n",
            "Created a chunk of size 1702, which is longer than the specified 1000\n",
            "Created a chunk of size 1615, which is longer than the specified 1000\n",
            "Created a chunk of size 1016, which is longer than the specified 1000\n",
            "Created a chunk of size 1887, which is longer than the specified 1000\n",
            "Created a chunk of size 2394, which is longer than the specified 1000\n",
            "Created a chunk of size 2017, which is longer than the specified 1000\n",
            "Created a chunk of size 1824, which is longer than the specified 1000\n",
            "Created a chunk of size 1588, which is longer than the specified 1000\n",
            "Created a chunk of size 1672, which is longer than the specified 1000\n",
            "Created a chunk of size 1678, which is longer than the specified 1000\n",
            "Created a chunk of size 1721, which is longer than the specified 1000\n",
            "Created a chunk of size 2739, which is longer than the specified 1000\n",
            "Created a chunk of size 1978, which is longer than the specified 1000\n",
            "Created a chunk of size 1591, which is longer than the specified 1000\n",
            "Created a chunk of size 1477, which is longer than the specified 1000\n",
            "Created a chunk of size 1034, which is longer than the specified 1000\n",
            "Created a chunk of size 1025, which is longer than the specified 1000\n",
            "Created a chunk of size 12487, which is longer than the specified 1000\n",
            "Created a chunk of size 3409, which is longer than the specified 1000\n",
            "Created a chunk of size 28779, which is longer than the specified 1000\n",
            "Created a chunk of size 9344, which is longer than the specified 1000\n",
            "Created a chunk of size 8742, which is longer than the specified 1000\n",
            "Created a chunk of size 2733, which is longer than the specified 1000\n",
            "Created a chunk of size 1842, which is longer than the specified 1000\n",
            "Created a chunk of size 4688, which is longer than the specified 1000\n",
            "Created a chunk of size 9278, which is longer than the specified 1000\n",
            "Created a chunk of size 7108, which is longer than the specified 1000\n",
            "Created a chunk of size 5295, which is longer than the specified 1000\n",
            "Created a chunk of size 4497, which is longer than the specified 1000\n",
            "Created a chunk of size 3035, which is longer than the specified 1000\n",
            "Created a chunk of size 5293, which is longer than the specified 1000\n",
            "Created a chunk of size 23409, which is longer than the specified 1000\n",
            "Created a chunk of size 2916, which is longer than the specified 1000\n",
            "Created a chunk of size 13488, which is longer than the specified 1000\n",
            "Created a chunk of size 19609, which is longer than the specified 1000\n",
            "Created a chunk of size 9183, which is longer than the specified 1000\n",
            "Created a chunk of size 1606, which is longer than the specified 1000\n",
            "Created a chunk of size 7562, which is longer than the specified 1000\n",
            "Created a chunk of size 2578, which is longer than the specified 1000\n"
          ]
        }
      ],
      "source": [
        "loader = TextLoader(\"constitution.txt\")\n",
        "\n",
        "documents = loader.load()\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "docs = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoq8f5j9hBed"
      },
      "source": [
        "## **Connect to Neo4j and load the embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e4acnsSkiT2I"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "# Input your Neo4j password\n",
        "NEO4J_PASSWORD = getpass('Your Neo4j password: ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VTYStLqieMhQ"
      },
      "outputs": [],
      "source": [
        "# Neo4jVector requires the Neo4j database credentials\n",
        "\n",
        "url = \"neo4j+s://49920e97.databases.neo4j.io:7687\"\n",
        "username = \"neo4j\"\n",
        "password = NEO4J_PASSWORD\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SBWQpdwUeW2P"
      },
      "outputs": [],
      "source": [
        "# The Neo4jVector Module will connect to Neo4j and create a vector index if needed.\n",
        "\n",
        "db = Neo4jVector.from_documents(\n",
        "    docs, OpenAIEmbeddings(), url=url, username=username, password=password\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-7jrKxcPhLnZ"
      },
      "source": [
        "## **Query the DB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5qdHr7Y6f5Al"
      },
      "outputs": [],
      "source": [
        "query = \"Do I have freedom from a nationalized religion?\"\n",
        "docs_with_score = db.similarity_search_with_score(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XicQKktfzuD",
        "outputId": "c8c9a076-6ee3-48f1-c0b6-cc1622a72924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Score:  0.8886802792549133\n",
            "Congress shall make no law respecting an establishment of \n",
            "religion, or prohibiting the free exercise thereof; or \n",
            "abridging the freedom of speech, or of the press; of the right \n",
            "of the people peaceably to assemble, and to petition the \n",
            "Government for a redress of grievances.\n",
            "---------------------------------------------------------------------------\n",
            "                                   * * * * *                              \n",
            "\\12\\The first ten amendments of the Constitution of the United States \n",
            "(and two others, one of which failed of ratification and the other \n",
            "which later became the 27th amendment) were proposed to the \n",
            "legislatures of the several States by the First Congress on September \n",
            "25, 1789. The first ten amendments were ratified by the following \n",
            "States, and the notifications of ratification by the Governors thereof \n",
            "were successively communicated by the President to Congress: New \n",
            "Jersey, November 20, 1789; Maryland, December 19, 1789; North Carolina, \n",
            "December 22, 1789; South Carolina, January 19, 1790; New Hampshire, \n",
            "January 25, 1790; Delaware, January 28, 1790; New York, February 24, \n",
            "1790; Pennsylvania, March 10, 1790; Rhode Island, June 7, 1790; \n",
            "Vermont, November 3, 1791; and Virginia, December 15, 1791.\n",
            "                                   * * * * *                              \n",
            "Ratification was completed on December 15, 1791.\n",
            "                                   * * * * *                              \n",
            "The amendments were subsequently ratified by the legislatures of \n",
            "Massachusetts, March 2, 1939; Georgia, March 18, 1939; and Connecticut, \n",
            "April 19, 1939.\n",
            "                                   * * * * *                              \n",
            "\\13\\Only the 13th, 14th, 15th, and 16th articles of amendment had \n",
            "numbers assigned to them at the time of ratification.\n",
            "---------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.8850306272506714\n",
            "B\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.8841608166694641\n",
            "D\n",
            "--------------------------------------------------------------------------------\n",
            "--------------------------------------------------------------------------------\n",
            "Score:  0.8812307715415955\n",
            "C\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for doc, score in docs_with_score:\n",
        "    print(\"-\" * 80)\n",
        "    print(\"Score: \", score)\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 80)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMg6fdJ0LTnHcON9lOnJcJv",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
